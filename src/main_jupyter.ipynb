{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MusicLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "from configparser import ConfigParser\n",
    "import numpy as np\n",
    "%pylab inline\n",
    "\n",
    "from log import initLog, writeLog\n",
    "from timer import timer_start, timer_stop\n",
    "import file_actions\n",
    "import extract_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the config file\n",
    "config = ConfigParser()\n",
    "cfile = os.path.join(os.getcwd(), \"config.ini\")\n",
    "config.read(cfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logs initialization\n",
    "initLog(config)\n",
    "writeLog(\"info\", \"Program restarted\")\n",
    "\n",
    "# Python version info\n",
    "sys.path.append(os.path.abspath(os.getcwd()))\n",
    "python_version = sys.version_info.major\n",
    "writeLog(\"debug\", \"Python version: {}\".format(sys.version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data, extracting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_actions.folder_mp3_to_wav()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = os.listdir(\"../data/samples\")\n",
    "labels = [f.title() for f in folders]\n",
    "writeLog(\"info\", \"Folders in ../data/samples: {}\".format(folders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recover_saved_data():\n",
    "    \"\"\"Recover previously saved data\"\"\"\n",
    "    X = np.loadtxt(\"../tmp/X.csv\")\n",
    "    Y = np.loadtxt(\"../tmp/Y.csv\").astype(\"int\")\n",
    "    with open(\"../tmp/flabels.txt\", \"r\") as f:\n",
    "        flabels = [l.strip() for l in f.readlines()]\n",
    "    with open(\"../tmp/trackNames.txt\", \"r\") as f:\n",
    "        trackNames = [l.strip() for l in f.readlines()]\n",
    "    return X, Y, flabels, trackNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def file_name_to_track_name(fn):\n",
    "    \"\"\"Make a clean track name with the file name\"\"\"\n",
    "    tn = os.path.split(fn)[1]\n",
    "    tn = os.path.splitext(tn)[0]\n",
    "    return tn.lstrip('0123456789').lstrip(' -.')\n",
    "\n",
    "def create_data_from_files():\n",
    "    \"\"\"Compute the data (features, labels,...) from audio files and save the results\"\"\"\n",
    "    X = []\n",
    "    Y = []\n",
    "    trackNames = []\n",
    "    # Extract all the features\n",
    "    for i, f in enumerate(folders):\n",
    "        samples = glob.glob(\"../data/samples/{}/*.wav\".format(f))\n",
    "        for s in samples:\n",
    "            # es = file_actions.extract_sound_light(s, ratio=0.5, duration=10) # test light\n",
    "            es = file_actions.extract_sound(s)\n",
    "            esm = file_actions.convert_to_mono(es[0])[0]\n",
    "            d = {\"label\": i, \"sound\": esm, \"params\": es[1], \"file\": s}\n",
    "            X.append(extract_features.extract_all_features(d))\n",
    "            Y.append(d[\"label\"])\n",
    "            trackNames.append(file_name_to_track_name(d[\"file\"]))\n",
    "    # Make arrays from the data\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    flabels = extract_features.features_labels()\n",
    "    # Save the data and returning it\n",
    "    np.savetxt(\"../tmp/X.csv\", X)\n",
    "    np.savetxt(\"../tmp/Y.csv\", Y)\n",
    "    with open(\"../tmp/flabels.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(flabels))\n",
    "    with open(\"../tmp/trackNames.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(trackNames))\n",
    "    writeLog(\"info\", \"File extraction finished\")\n",
    "    return X, Y, flabels, trackNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_saved = False\n",
    "\n",
    "if load_saved:\n",
    "    try:\n",
    "        X, Y, flabels, trackNames = recover_saved_data()\n",
    "    except Exception:\n",
    "        writeLog(\"warn\", \"Could not load the data, will extract from files.\")\n",
    "        X, Y, flabels, trackNames = create_data_from_files()\n",
    "else:\n",
    "    X, Y, flabels, trackNames = create_data_from_files()\n",
    "\n",
    "print(X.shape)\n",
    "# print(X[:, :4])\n",
    "# print(Y)\n",
    "# print(flabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shuffle all the samples\n",
    "data_group = list(zip(X, Y, trackNames))\n",
    "random.shuffle(data_group)\n",
    "X, Y, trackNames = list(zip(*data_group))\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "trackNames = np.array(trackNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize and/or scale the data\n",
    "from sklearn import preprocessing\n",
    "X_s = preprocessing.scale(X)\n",
    "X_n = preprocessing.normalize(X)\n",
    "X_sn = preprocessing.normalize(X_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_ratio = 0.75\n",
    "sep_ind = int(tr_ratio*len(Y))\n",
    "\n",
    "# Training samples\n",
    "X_tr = X[:sep_ind, :]\n",
    "X_tr_s = X_s[:sep_ind, :]\n",
    "X_tr_n = X_n[:sep_ind, :]\n",
    "X_tr_sn = X_sn[:sep_ind, :]\n",
    "Y_tr = Y[:sep_ind]\n",
    "trackNames_tr = trackNames[:sep_ind]\n",
    "\n",
    "# Test samples\n",
    "X_te = X[sep_ind:, :]\n",
    "X_te_s = X_s[sep_ind:, :]\n",
    "X_te_n = X_n[sep_ind:, :]\n",
    "X_te_sn = X_sn[sep_ind:, :]\n",
    "Y_te = Y[sep_ind:]\n",
    "trackNames_te = trackNames[sep_ind:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_feature_per_label():\n",
    "    fig = plt.figure(figsize=(12, 2*X.shape[1])) # (width, height)\n",
    "    \n",
    "    for idx in range(X.shape[1]):\n",
    "        for (number, Xi, legend) in [(1, X, '(not scaled)'), (2, X_s, '(scaled)')]:\n",
    "            fig.add_subplot(X.shape[1],2,2*idx+number)\n",
    "            \n",
    "            for i in range(len(labels)):\n",
    "                indexes = [ind for ind in range(len(Y)) if Y[ind] == i]\n",
    "                xdata = range(len(indexes))\n",
    "                ydata = [Xi[ind, idx] for ind in indexes]\n",
    "            \n",
    "                plt.plot(xdata, ydata, 'o')\n",
    "            plt.title(\"{} {}\".format(flabels[idx], legend), fontsize=16)\n",
    "    \n",
    "    plt.tight_layout() # improve spacing between subplots\n",
    "\n",
    "# plot_feature_per_label()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_fit(classifier, X_tr, Y_tr, X_te):\n",
    "    \"\"\"Train the classifier using X_tr and Y_tr, and fit X_te\"\"\"\n",
    "    classifier.fit(X_tr, Y_tr)\n",
    "    return classifier.predict(X_te).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up a stratified 3-fold cross-validation\n",
    "from sklearn import model_selection\n",
    "folds = model_selection.StratifiedKFold(3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validate(classifier, design_matrix, labels, cv_folds):\n",
    "    \"\"\"Perform a cross-validation and returns the predictions.\"\"\"\n",
    "    pred = np.zeros(labels.shape)\n",
    "    for tr, te in cv_folds.split(design_matrix, labels):\n",
    "        # Restrict data to train/test folds\n",
    "        Xtr = design_matrix[tr, :]\n",
    "        ytr = labels[tr]\n",
    "        Xte = design_matrix[te, :]\n",
    "\n",
    "        # Fit classifier\n",
    "        classifier.fit(Xtr, ytr)\n",
    "\n",
    "        # Predict the label with the features\n",
    "        yte_pred = classifier.predict(Xte)\n",
    "        pred[te] = yte_pred[:]\n",
    "    return pred.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix'):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    # print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analyse_results(Ypred, Y, trackNames=trackNames, details=1):\n",
    "    \"\"\"\n",
    "    Analyse the results, several levels of details:\n",
    "    0: Print the score\n",
    "    1: Print the score and confusion matrix\n",
    "    2: Print the score, confusion matrix, and prediction for each track\n",
    "    \"\"\"\n",
    "    print(\"Labels:    \", Y)\n",
    "    print(\"Prediction:\", Ypred)\n",
    "    \n",
    "    score = sum([1 if Ypred[i] == yi else 0 for i, yi in enumerate(Y)])\n",
    "    ratio = score / len(Y)\n",
    "    writeLog(\"info\", \"Score: {:03f}  ({}/{})\".format(ratio, score, len(Y)))\n",
    "    \n",
    "    if details >= 1:\n",
    "        cnf_matrix = confusion_matrix(Y, Ypred)\n",
    "        np.set_printoptions(precision=2)\n",
    "\n",
    "        # Plot non-normalized confusion matrix\n",
    "        plt.figure()\n",
    "        plot_confusion_matrix(cnf_matrix, classes=labels, title='Confusion matrix')\n",
    "        plt.show()\n",
    "    if details >= 2:\n",
    "        for i, track in enumerate(trackNames):\n",
    "            if Ypred[i] != Y[i]:\n",
    "                res = \"{} -> {} ({})\".format(track, labels[Ypred[i]], labels[Y[i]])\n",
    "                res = \"\\033[91m{}\\033[0m\".format(res)\n",
    "            else:\n",
    "                res = \"{} -> {}\".format(track, labels[Y[i]])\n",
    "            print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "clf_lr = linear_model.LogisticRegression(C=1e6) # high C means no regularization\n",
    "\n",
    "# Ypred_lr = train_and_fit(clf_lr, X_tr, Y_tr, X_te)\n",
    "# analyse_results(Ypred_lr, Y_te, trackNames_te)\n",
    "\n",
    "# Ypred_lr = cross_validate(clf_lr, X, Y, folds)\n",
    "# analyse_results(Ypred_lr, Y, trackNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "clf_lr_s = linear_model.LogisticRegression(C=1e6) # high C means no regularization\n",
    "\n",
    "# Ypred_lr_s = train_and_fit(clf_lr_s, X_tr_s, Y_tr, X_te_s)\n",
    "# analyse_results(Ypred_lr_s, Y_te, trackNames_te, details=2)\n",
    "\n",
    "Ypred_lr_s = cross_validate(clf_lr_s, X_s, Y, folds)\n",
    "analyse_results(Ypred_lr_s, Y, trackNames, details=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn import linear_model\n",
    "\n",
    "# clf_lrr_s = linear_model.LogisticRegression(C=1) # high C means no regularization\n",
    "\n",
    "# Ypred_lrr_s = train_and_fit(clf_lrr_s, X_tr_s, Y_tr, X_te_s)\n",
    "# analyse_results(Ypred_lrr_s, Y_te, trackNames_te, details=2)\n",
    "\n",
    "# Ypred_lrr_s = cross_validate(clf_lrr_s, X_s, Y, folds)\n",
    "# analyse_results(Ypred_lrr_s, Y, trackNames, details=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn import ensemble\n",
    "\n",
    "# clf_rf_s = ensemble.RandomForestRegressor()\n",
    "\n",
    "# Ypred_rf_s = train_and_fit(clf_rf_s, X_tr_s, Y_tr, X_te_s)\n",
    "# analyse_results(Ypred_rf_s, Y_te, trackNames_te, details=2)\n",
    "\n",
    "# Ypred_rf_s = cross_validate(clf_rf_s, X, Y, folds)\n",
    "# analyse_results(Ypred_rf_s, Y, trackNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from sklearn import neighbors\n",
    "\n",
    "# clf_k = neighbors.KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "\n",
    "# Ypred_k = cross_validate(clf_k, X_s, Y, folds)\n",
    "# analyse_results(Ypred_k, Y, trackNames, details=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
